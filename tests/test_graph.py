from typing import Any
from pydantic import SerializationInfo, SerializeAsAny, SerializerFunctionWrapHandler, field_serializer
import pytest
from krnel.graph import OpSpec
from krnel.graph.op_spec import find_subclass_of, graph_deserialize, graph_serialize


class ExampleDataSource(OpSpec):
    """Example op spec for testing."""
    dataset_name: str
    import_date: str

DATA_SOURCE_A = ExampleDataSource(
    dataset_name="test",
    import_date="2023-01-01",
)
DATA_SOURCE_A__UUID = "ExampleDataSource-PdjhDBdRqA_APc0oDl4T5fEVUVs163q6riQgiD7_eDw"
DATA_SOURCE_A__JSON_PARTIAL = {
    "type": "ExampleDataSource",
    "dataset_name": "test",
    "import_date": "2023-01-01",
}


class DatasetDoubleSize(OpSpec):
    """Operation that doubles the size of the dataset!"""
    power_level: str = "DOUBLE"
    source_dataset: ExampleDataSource

OPERATION_A = DatasetDoubleSize(
    source_dataset=DATA_SOURCE_A,
)
OPERATION_A__UUID = "DatasetDoubleSize-xuSBlrAQIzBEFd3UwuBfFixRLDShHEul54jFJUojl2A"
OPERATION_A__JSON_PARTIAL = {
    "type": "DatasetDoubleSize",
    # Partial serialization for uuid (internal):
    "source_dataset": DATA_SOURCE_A__UUID,
    "power_level": "DOUBLE",
}
OPERATION_A__JSON_GRAPH = {
    "outputs": [OPERATION_A__UUID],
    "nodes": {
        OPERATION_A__UUID: OPERATION_A__JSON_PARTIAL,
        DATA_SOURCE_A__UUID: DATA_SOURCE_A__JSON_PARTIAL,
    }
}

OPERATION_B = DatasetDoubleSize(
    source_dataset=DATA_SOURCE_A,
    power_level="TRIPLE",
)
OPERATION_B__UUID = "DatasetDoubleSize-OAnNuc0FxlFCaUpr7fUAGCwzqYzm7zvGXqqGn7o3_ZA"
OPERATION_B__JSON_PARTIAL = {
    "type": "DatasetDoubleSize",
    # Partial serialization for uuid (internal):
    "source_dataset": DATA_SOURCE_A__UUID,
    "power_level": "TRIPLE",
}

class CombineTwoOperations(OpSpec):
    op_a: OpSpec
    op_b: OpSpec
OPERATION_COMBINE_TWO = CombineTwoOperations(
    op_a=OPERATION_A,
    op_b=DatasetDoubleSize(source_dataset=DATA_SOURCE_A, power_level="TRIPLE"),
)
OPERATION_COMBINE_TWO__UUID = "CombineTwoOperations-lQDRhkfRtiwoIg4lWQ6-GOUPBocVgcGoCbkc8C2z7Ic"
OPERATION_COMBINE_TWO__JSON_PARTIAL = {
    "type": "CombineTwoOperations",
    "op_a": OPERATION_A__UUID,
    "op_b": OPERATION_B__UUID,
}
OPERATION_COMBINE_TWO__JSON_GRAPH = {
    "outputs": [OPERATION_COMBINE_TWO__UUID],
    "nodes": {
        OPERATION_COMBINE_TWO__UUID: OPERATION_COMBINE_TWO__JSON_PARTIAL,
        OPERATION_A__UUID: OPERATION_A__JSON_PARTIAL,
        OPERATION_B__UUID: OPERATION_B__JSON_PARTIAL,
        DATA_SOURCE_A__UUID: DATA_SOURCE_A__JSON_PARTIAL,
    }
}

def test_op_spec_immutability():
    """Test that OpSpec instances are immutable."""
    spec = DATA_SOURCE_A
    assert spec.dataset_name == "test"
    assert spec.import_date == "2023-01-01"

    # Try to mutate and expect immutability error (pydantic.ValidationError)
    from pydantic_core import ValidationError
    with pytest.raises(ValidationError):
        spec.dataset_name = "changed"


def test_op_spec_uuid():
    """Test that OpSpec generates a UUID."""
    spec = DATA_SOURCE_A
    spec2 = OPERATION_A

    # Update to match the actual UUID generated by the implementation (with 'type' included)
    assert spec.uuid == DATA_SOURCE_A__UUID
    assert spec2.uuid == OPERATION_A__UUID


def test_op_spec_uuid_consistency():
    """Test that identical specs have the same UUID."""
    spec1 = ExampleDataSource(dataset_name="test", import_date="2023-01-01")
    spec2 = ExampleDataSource(dataset_name="test", import_date="2023-01-01")
    spec3 = ExampleDataSource(dataset_name="bar", import_date="2023-01-01")

    assert spec1.uuid == DATA_SOURCE_A__UUID
    assert spec2.uuid == spec1.uuid
    assert spec3.uuid != spec1.uuid


def test_op_spec_serialization():
    """Test OpSpec serialization behavior."""
    data = DATA_SOURCE_A
    op_a = OPERATION_A

    # Test serialization of a single OpSpec instance contains child UUIDs
    data_dict = data.model_dump()
    assert data_dict == DATA_SOURCE_A__JSON_PARTIAL
    op_a_dict = op_a.model_dump()
    assert op_a_dict == OPERATION_A__JSON_PARTIAL

def test_op_spec_graph_serialization():
    """Test serializing a graph of OpSpec instances."""
    op_a = OPERATION_A
    op_b = OPERATION_B
    op_combined = OPERATION_COMBINE_TWO
    op_a_graphdict = graph_serialize(op_a)
    assert op_a_graphdict == OPERATION_A__JSON_GRAPH
    op_combined_graphdict = graph_serialize(op_combined)
    assert op_combined_graphdict == OPERATION_COMBINE_TWO__JSON_GRAPH

def test_op_spec_graph_deserialization():
    """Test deserializing a graph of OpSpec instances."""
    serialized = OPERATION_COMBINE_TWO__JSON_GRAPH
    [op] = graph_deserialize(serialized)
    assert op == OPERATION_COMBINE_TWO
    assert op.uuid == OPERATION_COMBINE_TWO__UUID
    assert isinstance(op, CombineTwoOperations)
    assert isinstance(op.op_a, DatasetDoubleSize)
    assert op.op_a.uuid == OPERATION_A__UUID
    assert isinstance(op.op_b, DatasetDoubleSize)
    assert op.op_b.uuid == OPERATION_B__UUID


def test_op_spec_reserialization_fails():
    """Test that a OpSpec fails to deserialize if type is missing."""
    serialized_graph = {
        "outputs": ["abcd"],
        "nodes": {
            "abcd": {
                "type": "SomeMissingType",
            }
        }
    }
    with pytest.raises(ValueError, match="Class with name SomeMissingType not found in OpSpec hierarchy"):
        graph_deserialize(serialized_graph)

def test_op_spec_parents():
    class SomeComparison(OpSpec):
        op_a: DatasetDoubleSize
        op_b: DatasetDoubleSize

    some_comparison = SomeComparison(
        op_a=OPERATION_A,
        op_b=DatasetDoubleSize(source_dataset=DATA_SOURCE_A),
    )

    assert OPERATION_A.get_parents() == {DATA_SOURCE_A} # type: ignore[reportUnhashable]



def test_get_parents_of_type_specific():
    """Test get_parents with a specific type filters parents."""
    class ParentA(OpSpec):
        foo: str
    class ParentB(OpSpec):
        bar: int
    class Child(OpSpec):
        a: ParentA
        b: ParentB
    pa = ParentA(foo="x")
    pb = ParentB(bar=1)
    c = Child(a=pa, b=pb)
    parents = c.get_parents()
    assert parents == {pa, pb}  # type: ignore[reportUnhashable]



def test_get_parents_recursive():
    """Test get_parents with recursive=True collects all ancestors."""
    class Grandparent(OpSpec):
        foo: str
    class Parent(OpSpec):
        gp: Grandparent
    class Child(OpSpec):
        p: Parent
    gp = Grandparent(foo="z")
    p = Parent(gp=gp)
    c = Child(p=p)
    parents = c.get_parents(recursive=True)
    assert {x for x in parents} == {p, gp}  # type: ignore[reportUnhashable]


def test_get_parents_no_parents():
    """Test get_parents returns empty set if no parents."""
    class Standalone(OpSpec):
        foo: int
    s = Standalone(foo=1)
    assert s.get_parents() == set()


def test_serialize_as_any_annotation_working():
    # https://github.com/pydantic/pydantic/issues/12121
    from pydantic import BaseModel, SerializeAsAny
    class User(BaseModel):
        name: str
    class UserLogin(User):
        password: str
    class OuterModel(BaseModel):
        as_any: SerializeAsAny[User]
        as_user: User

    user = UserLogin(name='pydantic', password='password')
    assert OuterModel(as_any=user, as_user=user).model_dump() == {
        'as_any': {'name': 'pydantic', 'password': 'password'},
        'as_user': {'name': 'pydantic'},
    }

@pytest.mark.skip(reason="upstream bug in pydantic")
def test_serialize_as_any_annotation_broken():
    # https://github.com/pydantic/pydantic/issues/12121
    from pydantic import BaseModel, SerializeAsAny
    class User(BaseModel):
        name: str
    class UserLogin(User):
        password: str
    class OuterModel(BaseModel):
        @field_serializer('*', mode='wrap')
        def custom_field_serializer(v: Any, nxt: SerializerFunctionWrapHandler):
            return nxt(v)
        as_any: SerializeAsAny[User]
        as_user: User

    user = UserLogin(name='pydantic', password='password')
    assert OuterModel(as_any=user, as_user=user).model_dump() == {
        'as_any': {'name': 'pydantic', 'password': 'password'},
        'as_user': {'name': 'pydantic'},
    }


def test_serialize_opspec_field_list():
    """Test that OpSpec fields are serialized correctly."""
    class ExampleOp(OpSpec):
        name: str
        datasets: list[OpSpec] = []

    op1 = ExampleOp(name="op1")
    op2 = ExampleOp(name="op2", datasets=[op1])

    serialized = op2.model_dump()
    assert serialized['name'] == "op2"
    assert len(serialized['datasets']) == 1
    assert serialized['datasets'][0] == op1.uuid

    graph_serialized = graph_serialize(op2)
    [reserialized] = graph_deserialize(graph_serialized)
    assert reserialized == op2
    assert reserialized.uuid == op2.uuid

def test_serialize_opspec_field_dict():
    """Test that OpSpec fields are serialized correctly."""
    class ExampleDictOp(OpSpec):
        name: str
        datasets: dict[str, OpSpec] = {}

    op1 = ExampleDictOp(name="op1", datasets={})
    op2 = ExampleDictOp(name="op2", datasets={"dataset1": op1})

    serialized = op2.model_dump()
    assert serialized['name'] == "op2"
    assert len(serialized['datasets']) == 1
    assert serialized['datasets']['dataset1'] == op1.uuid

    graph_serialized = graph_serialize(op2)
    [reserialized] = graph_deserialize(graph_serialized)
    assert reserialized == op2
    assert reserialized.uuid == op2.uuid


def test_two_subclasses_same_name_should_fail():
    """Test that two subclasses with the same name raises an error."""
    class BaseOp(OpSpec):
        pass

    class BaseOp(OpSpec):
        int_field: int

    with pytest.raises(ValueError, match="Multiple subclasses found for BaseOp"):
        print(OpSpec.__subclasses__())
        find_subclass_of(OpSpec, "BaseOp")


def test_deserialize_missing_node_uuid_should_fail():
    """Test that deserializing a graph with a missing node UUID raises an error."""
    serialized_graph = {
        "outputs": ["some-uuid"],
        "nodes": {
            # "some-uuid" is missing
            "other-uuid": {
                "type": "ExampleDataSource",
                "dataset_name": "test",
                "import_date": "2023-01-01",
            }
        }
    }
    with pytest.raises(ValueError, match="Node with UUID some-uuid not found in graph"):
        graph_deserialize(serialized_graph)


def test_deserialize_uuid_mismatch_should_fail():
    """Test that deserializing a graph whose UUID no longer matches the content raises an error."""
    serialized_graph = {
        "outputs": ["some-uuid"],
        "nodes": {
            # incorrect UUID
            "some-uuid": {
                "type": "ExampleDataSource",
                "dataset_name": "test",
                "import_date": "2023-01-01",
            }
        }
    }
    with pytest.raises(ValueError, match="UUID mismatch"):
        graph_deserialize(serialized_graph)


def test_deserialize_cycle_should_fail():
    """Test that deserializing a graph with a cycle raises an error."""
    serialized_graph = {
        "outputs": ["node-a"],
        "nodes": {
            "node-a": {
                "type": "DatasetDoubleSize",
                "power_level": "DOUBLE",
                "source_dataset": "node-b",  # points to node-b
            },
            "node-b": {
                "type": "DatasetDoubleSize",
                "power_level": "DOUBLE",
                "source_dataset": "node-a",  # points back to node-a, creating a cycle
            }
        }
    }
    with pytest.raises(ValueError, match="Cycle detected in graph"):
        graph_deserialize(serialized_graph)


def test_deserializing_unreachable_nodes_should_fail():
    """Test that deserializing a graph with unreachable nodes raises an error."""
    serialized_graph = {
        "outputs": [DATA_SOURCE_A__UUID],
        "nodes": {
            DATA_SOURCE_A__UUID: DATA_SOURCE_A__JSON_PARTIAL,
            "unreachable-node": {
                "type": "ExampleDataSource",
                "dataset_name": "unreachable",
                "import_date": "2023-01-01",
            }
        }
    }
    with pytest.raises(ValueError, match="Unreachable nodes in graph"):
        graph_deserialize(serialized_graph)