import pytest
from krnel.graph import ComputationSpec


class ExampleDataSource(ComputationSpec):
    """Example computation spec for testing."""
    dataset_name: str
    import_date: str

DATA_SOURCE_A = ExampleDataSource(
    dataset_name="test",
    import_date="2023-01-01",
)
DATA_SOURCE_A__HASH = "step-PdjhDBdRqA_APc0oDl4T5fEVUVs163q6riQgiD7_eDw"
DATA_SOURCE_A__JSON = {
    "type": "ExampleDataSource",
    "dataset_name": "test",
    "import_date": "2023-01-01",
}


class DatasetDoubleSize(ComputationSpec):
    """Operation that doubles the size of the dataset!"""
    power_level: str = "DOUBLE"
    source_dataset: ExampleDataSource

OPERATION_A = DatasetDoubleSize(
    source_dataset=DATA_SOURCE_A,
)
OPERATION_A__HASH = "step-XAr1rU5-LBnLkvBPTcIMMtp9div-SCF6eqGXpTejmYE"
OPERATION_A__JSON = {
    "type": "DatasetDoubleSize",
    # Full serialization:
    "source_dataset": {
        "type": "ExampleDataSource",
        "dataset_name": "test",
        "import_date": "2023-01-01",
    },
    "power_level": "DOUBLE",
}
OPERATION_A__JSON_PARTIAL = {
    "type": "DatasetDoubleSize",
    # Partial serialization for hash (internal):
    "source_dataset": "step-PdjhDBdRqA_APc0oDl4T5fEVUVs163q6riQgiD7_eDw",
    "power_level": "DOUBLE",
}


def test_computation_spec_immutability():
    """Test that ComputationSpec instances are immutable."""
    spec = DATA_SOURCE_A
    assert spec.dataset_name == "test"
    assert spec.import_date == "2023-01-01"

    # Try to mutate and expect immutability error (pydantic.ValidationError)
    from pydantic_core import ValidationError
    with pytest.raises(ValidationError):
        spec.dataset_name = "changed"


def test_computation_spec_content_hash():
    """Test that ComputationSpec generates a content hash."""
    spec = DATA_SOURCE_A
    spec2 = OPERATION_A

    # Update to match the actual hash generated by the implementation (with 'type' included)
    assert spec.content_hash == DATA_SOURCE_A__HASH
    assert spec2.content_hash == OPERATION_A__HASH


def test_computation_spec_hash_consistency():
    """Test that identical specs have the same hash."""
    spec1 = ExampleDataSource(dataset_name="test", import_date="2023-01-01")
    spec2 = ExampleDataSource(dataset_name="test", import_date="2023-01-01")
    spec3 = ExampleDataSource(dataset_name="bar", import_date="2023-01-01")

    assert spec1.content_hash == DATA_SOURCE_A__HASH
    assert spec2.content_hash == spec1.content_hash
    assert spec3.content_hash != spec1.content_hash


def test_computation_spec_serialization():
    """Test ComputationSpec serialization behavior."""
    data = DATA_SOURCE_A
    double_op = OPERATION_A

    # Test normal serialization (now includes 'type' field)
    normal_dict = double_op.model_dump()
    assert normal_dict == OPERATION_A__JSON

    # Test serialization with hash context (now includes 'type' field)
    hash_dict = double_op.model_dump(context={"for_hash": True})
    assert hash_dict == OPERATION_A__JSON_PARTIAL


def test_serialization_for_hash_false():
    """Test serialization when for_hash is False."""
    data = DATA_SOURCE_A
    result = data.model_dump(context={"for_hash": False})
    assert result == DATA_SOURCE_A__JSON

def test_computation_spec_reserialization():
    """Test that a ComputationSpec survives re-serialization."""
    serialized = OPERATION_A__JSON

    spec = ComputationSpec.model_validate(serialized)
    assert isinstance(spec, DatasetDoubleSize)
    assert isinstance(spec.source_dataset, ExampleDataSource)
    assert spec.source_dataset.dataset_name == "test"
    assert spec.content_hash == OPERATION_A__HASH

def test_computation_spec_hash_identity():
    """Test that a ComputationSpec can be re-serialized and retains its hash."""
    serialized = OPERATION_A__JSON

    spec = ComputationSpec.model_validate(serialized)
    assert isinstance(spec, DatasetDoubleSize)
    assert len({spec, OPERATION_A}) == 1 # type: ignore[reportUnhashable]


def test_computation_spec_reserialization_fails():
    """Test that a ComputationSpec fails to deserialize if type is missing."""
    serialized = {
        "type": "DoesNotExist",
    }

    from pydantic_core import ValidationError
    with pytest.raises(ValidationError):
        ComputationSpec.model_validate(serialized)

@pytest.mark.filterwarnings("ignore:A custom validator")
def test_computation_spec_type_field_serialization_fails():
    class InvalidComputationSpec(ComputationSpec):
        type: str = "InvalidComputationSpec"
        abc: str

    foo = InvalidComputationSpec(type="InvalidComputationSpec", abc="test")
    from pydantic_core import PydanticSerializationError
    with pytest.raises(PydanticSerializationError):
        foo.model_dump()


def test_computation_spec_parents():
    class SomeComparison(ComputationSpec):
        op_a: DatasetDoubleSize
        op_b: DatasetDoubleSize

    some_comparison = SomeComparison(
        op_a=OPERATION_A,
        op_b=DatasetDoubleSize(source_dataset=DATA_SOURCE_A),
    )

    assert OPERATION_A.get_parents() == {
        DATA_SOURCE_A
    }


def test_get_parents_of_type_none():
    """Test get_parents with of_type=None returns all direct parents."""


    class ParentA(ComputationSpec):
        foo: str
    class Child(ComputationSpec):
        parent: ParentA

    p = ParentA(foo="bar")
    c = Child(parent=p)
    parents = c.get_parents()
    assert parents == {p} # type: ignore[reportUnhashable]


def test_get_parents_of_type_specific():
    """Test get_parents with a specific type filters parents."""
    class ParentA(ComputationSpec):
        foo: str
    class ParentB(ComputationSpec):
        bar: int
    class Child(ComputationSpec):
        a: ParentA
        b: ParentB
    pa = ParentA(foo="x")
    pb = ParentB(bar=1)
    c = Child(a=pa, b=pb)
    parents_a = c.get_parents(of_type=ParentA)
    parents_b = c.get_parents(of_type=ParentB)
    assert {x for x in parents_a} == {pa}
    assert {x for x in parents_b} == {pb}


def test_get_parents_of_type_set():
    """Test get_parents with a set of types filters parents."""
    class ParentA(ComputationSpec):
        foo: str
    class ParentB(ComputationSpec):
        bar: int
    class Child(ComputationSpec):
        a: ParentA
        b: ParentB
    pa = ParentA(foo="x")
    pb = ParentB(bar=1)
    c = Child(a=pa, b=pb)
    parents = c.get_parents(of_type={ParentA, ParentB})
    assert {x for x in parents} == {pa, pb}


def test_get_parents_recursive():
    """Test get_parents with recursive=True collects all ancestors."""
    class Grandparent(ComputationSpec):
        foo: str
    class Parent(ComputationSpec):
        gp: Grandparent
    class Child(ComputationSpec):
        p: Parent
    gp = Grandparent(foo="z")
    p = Parent(gp=gp)
    c = Child(p=p)
    parents = c.get_parents(recursive=True)
    assert {x for x in parents} == {p, gp}  # type: ignore[reportUnhashable]


def test_get_recursive_filtered_indirect_parents():
    """
    Test get_parents with recursive=True and of_type will include indirect
    parents further up in the graph.
    """
    class Grandparent(ComputationSpec):
        foo: str
    class Parent(ComputationSpec):
        gp: Grandparent
    class Child(ComputationSpec):
        p: Parent
    gp = Grandparent(foo="z")
    p = Parent(gp=gp)
    c = Child(p=p)
    # Passing both `of_type` and `recursive` should ensure indirect parents are included.
    filtered_parents = c.get_parents(recursive=True, of_type=Grandparent)
    assert {x for x in filtered_parents} == {gp} # type: ignore[reportUnhashable]

def test_get_parents_no_parents():
    """Test get_parents returns empty set if no parents."""
    class Standalone(ComputationSpec):
        foo: int
    s = Standalone(foo=1)
    assert s.get_parents() == set()
