import pytest
from krnel.graph import ComputationSpec


class ExampleDataSource(ComputationSpec):
    """Example computation spec for testing."""
    dataset_name: str
    import_date: str


class DatasetDoubleSize(ComputationSpec):
    """Operation that doubles the size of the dataset!"""
    power_level: str = "DOUBLE"
    source_dataset: ExampleDataSource


# Test data instances and expected values
EXAMPLE_DATA_SOURCE = ExampleDataSource(dataset_name="test", import_date="2023-01-01")
DATASET_DOUBLE_SIZE = DatasetDoubleSize(source_dataset=EXAMPLE_DATA_SOURCE)

# Expected hashes
EXPECTED_EXAMPLE_DATA_SOURCE_HASH = "step-PdjhDBdRqA_APc0oDl4T5fEVUVs163q6riQgiD7_eDw"
EXPECTED_DATASET_DOUBLE_SIZE_HASH = "step-XAr1rU5-LBnLkvBPTcIMMtp9div-SCF6eqGXpTejmYE"

# Expected JSON content
EXPECTED_EXAMPLE_DATA_SOURCE_JSON = {
    "type": "ExampleDataSource",
    "dataset_name": "test",
    "import_date": "2023-01-01",
}
# Full serialization:
EXPECTED_DATASET_DOUBLE_SIZE_JSON = {
    "type": "DatasetDoubleSize",
    "source_dataset": {
        "type": "ExampleDataSource",
        "dataset_name": "test",
        "import_date": "2023-01-01",
    },
    "power_level": "DOUBLE",
}
# Partial serialization for hash (internal):
EXPECTED_DATASET_DOUBLE_SIZE_HASH_JSON = {
    "type": "DatasetDoubleSize",
    "source_dataset": "step-PdjhDBdRqA_APc0oDl4T5fEVUVs163q6riQgiD7_eDw",
    "power_level": "DOUBLE",
}

EXPECTED_RESERIALIZATION_JSON = {
    "type": "DatasetDoubleSize",
    "source_dataset": {
        "type": "ExampleDataSource",
        "dataset_name": "test",
        "import_date": "2023-01-01",
    },
    "power_level": "DOUBLE",
}


def test_computation_spec_immutability():
    """Test that ComputationSpec instances are immutable."""
    spec = EXAMPLE_DATA_SOURCE
    assert spec.dataset_name == "test"
    assert spec.import_date == "2023-01-01"

    # Try to mutate and expect immutability error (pydantic.ValidationError)
    from pydantic_core import ValidationError
    with pytest.raises(ValidationError):
        spec.dataset_name = "changed"


def test_computation_spec_content_hash():
    """Test that ComputationSpec generates a content hash."""
    spec = EXAMPLE_DATA_SOURCE
    spec2 = DATASET_DOUBLE_SIZE

    # Update to match the actual hash generated by the implementation (with 'type' included)
    assert spec.content_hash == EXPECTED_EXAMPLE_DATA_SOURCE_HASH
    assert spec2.content_hash == EXPECTED_DATASET_DOUBLE_SIZE_HASH


def test_computation_spec_hash_consistency():
    """Test that identical specs have the same hash."""
    spec1 = ExampleDataSource(dataset_name="test", import_date="2023-01-01")
    spec2 = ExampleDataSource(dataset_name="test", import_date="2023-01-01")
    spec3 = ExampleDataSource(dataset_name="bar", import_date="2023-01-01")

    assert spec1.content_hash == EXPECTED_EXAMPLE_DATA_SOURCE_HASH
    assert spec1.content_hash == spec2.content_hash
    assert spec3.content_hash != spec1.content_hash


def test_computation_spec_serialization():
    """Test ComputationSpec serialization behavior."""
    data = EXAMPLE_DATA_SOURCE
    double_op = DATASET_DOUBLE_SIZE

    # Test normal serialization (now includes 'type' field)
    normal_dict = double_op.model_dump()
    assert normal_dict == EXPECTED_DATASET_DOUBLE_SIZE_JSON

    # Test serialization with hash context (now includes 'type' field)
    hash_dict = double_op.model_dump(context={"for_hash": True})
    assert hash_dict == EXPECTED_DATASET_DOUBLE_SIZE_HASH_JSON


def test_serialization_for_hash_false():
    """Test serialization when for_hash is False."""
    data = EXAMPLE_DATA_SOURCE
    result = data.model_dump(context={"for_hash": False})
    assert result == EXPECTED_EXAMPLE_DATA_SOURCE_JSON

def test_computation_spec_reserialization():
    """Test that a ComputationSpec survives re-serialization."""
    serialized = EXPECTED_DATASET_DOUBLE_SIZE_JSON

    spec = ComputationSpec.model_validate(serialized)
    assert isinstance(spec, DatasetDoubleSize)
    assert isinstance(spec.source_dataset, ExampleDataSource)
    assert spec.source_dataset.dataset_name == "test"
    assert spec.content_hash == EXPECTED_DATASET_DOUBLE_SIZE_HASH

def test_computation_spec_reserialization_fails():
    """Test that a ComputationSpec fails to deserialize if type is missing."""
    serialized = {
        "type": "DoesNotExist",
    }

    from pydantic_core import ValidationError
    with pytest.raises(ValidationError):
        ComputationSpec.model_validate(serialized)

@pytest.mark.filterwarnings("ignore:A custom validator")
def test_computaion_spec_type_field_serialization_fails():
    class InvalidComputationSpec(ComputationSpec):
        type: str = "InvalidComputationSpec"
        abc: str

    foo = InvalidComputationSpec(type="InvalidComputationSpec", abc="test")
    from pydantic_core import PydanticSerializationError
    with pytest.raises(PydanticSerializationError):
        foo.model_dump()
